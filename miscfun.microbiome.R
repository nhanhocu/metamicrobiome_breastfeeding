# Functions for microbiome analysis and meta-analysis 
# Author: Nhan Ho
# This is an initial version customized for the project "Effects of exclusive breastfeeding on infant gut microbiota: a meta-analysis across studies and populations"
# A revised and more generally applicable version of these functions are available at: "https://github.com/nhanhocu/metamicrobiomeR"



#read multiple files in a path
#author: Nhan Ho (June 2017)
read.multi<-function (patht,patternt,assignt="no",study){
  setwd(patht)
  filenames <- list.files(path=patht, pattern=patternt)
  if (patternt==".txt"){
    tmp <- lapply(filenames, function(x) read.delim(file=x))
  }
  if (patternt==".csv"){
    tmp <- lapply(filenames, function(x) read.csv(file=x))
  }
  names(tmp)<-tolower(gsub(patternt,"", filenames))
  for (i in 1:length(names(tmp))){
    colnames(tmp[[i]])<-tolower(colnames(tmp[[i]]))
    tmp[[i]][,"study"]<-study
    if (assignt=="yes"){
      assign(names(tmp[i]),tmp[[names(tmp[i])]])
    }
  }
  return(tmp)
  rm(i)
}

# calculate average of alpha diversity for a specific rarefaction depth and compare between bf groups adjusted for age
# author: Nhan Ho (June 2017)
alpha.compare<-function(datlist,depth,mapfile,mapsampleid,comvar="bf",adjustvar="age.sample",longitudinal="yes",age.limit=100,standardize=FALSE,...){
  sapply(c("lme4","lmerTest","plyr","dplyr"), require, character.only = TRUE)
  #depth can be "max" or an order (number) of the depth in the list generated by alpha_rarefaction.py
  #bf variable must be factor with levels order=ebf, nebf and nbf
  alphamean<-matrix(NA, nrow=length(names(datlist)),ncol=(ncol(datlist[[1]])-3))
    rownames(alphamean)<-names(datlist)
    colnames(alphamean)<-colnames(datlist[[1]])[-c(1:3)]
    for (i in 1: length(names(datlist))){
      dat.a<-datlist[[i]]
      raredepth<-unique(dat.a$sequences.per.sample)[as.numeric(as.character(depth))]
      if (depth=="max"){
        raredepth<-max(unique(dat.a$sequences.per.sample))
      }
      dat.a[,-c(1:3)]<-lapply(dat.a[,-c(1:3)],as.character)
      dat.a[,-c(1:3)]<-lapply(dat.a[,-c(1:3)],as.numeric)
      dat.mean<-ddply(dat.a, .(sequences.per.sample), colwise(mean))
      alphamean[i,]<-matrix(unlist(dat.mean[dat.mean$sequences.per.sample==raredepth,-c(1:3)]),nrow=1)
    }
    alphamean<-as.data.frame(t(alphamean))
    alphamean$sampleid<-sub('.*x', '', rownames(alphamean)) #dirty fix to remove added x to samplenames started with number e.g. Haiti data
    #standardize alpha
    alphameans<-mutate_at(alphamean,.vars=names(datlist),.funs=function(x){(x-mean(x,na.r=T))/sd(x,na.rm=T)})
    mapfile[,mapsampleid]<-tolower(mapfile[,mapsampleid])
    #get sample only in mapfile (all age)
    alphamean<-alphamean[alphamean$sampleid %in% mapfile[,mapsampleid],]
    alphameans<-alphameans[alphameans$sampleid %in% mapfile[,mapsampleid],]
    #merge with mapfile
    #apply age limit for comparison
    mapfile<-mapfile[mapfile$age.sample<=age.limit,]
    if (standardize==FALSE){
      alphamap<-merge(mapfile,alphamean,by.x=mapsampleid,by.y="sampleid")
    }
    if (standardize==TRUE){
      alphamap<-merge(mapfile,alphameans,by.x=mapsampleid,by.y="sampleid")
    }
    #convert comvar to continuous for trend testing
    alphamap[,"comvarnum"]<-as.numeric(alphamap[,comvar]) # for trend testing
    comvarnum<-"comvarnum"
  nlevcom<-nlevels(as.factor(as.character(alphamap[,comvar])))
  alphasum<-matrix(NA,ncol=16,nrow=length(names(datlist)))
  rownames(alphasum)<-names(datlist)
  colnames(alphasum)<-c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age","estimate.conbf","se.conbf","teststat.conbf","pval.conbf")
    for (j in 1: length(names(datlist))){
      #mixed model
      if (longitudinal=="yes"){
        sumfit.j<-summary(glmer(as.formula(paste(names(datlist)[j],paste(c(comvar,adjustvar,"(1|personid)"),collapse="+"),sep="~")), data=alphamap,family=gaussian(link="identity")))
        if (nlevcom==3){
          alphasum[j,c("estimate.nebf","se.nebf","teststat.nebf","estimate.nbf","se.nbf","teststat.nbf","estimate.age","se.age","teststat.age")]<-c(sumfit.j$coefficients[2,],sumfit.j$coefficients[3,],sumfit.j$coefficients[4,])
          z.nebf<-alphasum[j,"estimate.nebf"]/alphasum[j,"se.nebf"]
          alphasum[j,"pval.nebf"]<- 2*pnorm(-abs(z.nebf))
          z.nbf<-alphasum[j,"estimate.nbf"]/alphasum[j,"se.nbf"]
          alphasum[j,"pval.nbf"]<- 2*pnorm(-abs(z.nbf))
          z.age<-alphasum[j,"estimate.age"]/alphasum[j,"se.age"]
          alphasum[j,"pval.age"]<- 2*pnorm(-abs(z.age))
          #treat bf as continuous to test for trend adjusted for age
          sumfit.conbf.j<-summary(glmer(as.formula(paste(names(datlist)[j],paste(c(comvarnum,adjustvar,"(1|personid)"),collapse="+"),sep="~")), data=alphamap,family=gaussian(link="identity")))
          alphasum[j,c("estimate.conbf","se.conbf","teststat.conbf")]<-sumfit.conbf.j$coefficients[2,]
          z.conbf<-alphasum[j,"estimate.conbf"]/alphasum[j,"se.conbf"]
          alphasum[j,"pval.conbf"]<- 2*pnorm(-abs(z.conbf))
        }
        if (nlevcom==2){
          alphasum[j,c("estimate.nebf","se.nebf","teststat.nebf","estimate.age","se.age","teststat.age")]<-c(sumfit.j$coefficients[2,],sumfit.j$coefficients[3,])
          z.nebf<-alphasum[j,"estimate.nebf"]/alphasum[j,"se.nebf"]
          alphasum[j,"pval.nebf"]<- 2*pnorm(-abs(z.nebf))
          z.age<-alphasum[j,"estimate.age"]/alphasum[j,"se.age"]
          alphasum[j,"pval.age"]<- 2*pnorm(-abs(z.age))
        }
      }
      #linear model
      if (longitudinal=="no"){
        sumfit.j<-summary(glm(as.formula(paste(names(datlist)[j],paste(c(comvar,adjustvar),collapse="+"),sep="~")), data=alphamap,family="gaussian"))
        if (nlevcom==3){
          alphasum[j,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(sumfit.j$coefficients[2,],sumfit.j$coefficients[3,],sumfit.j$coefficients[4,])
          #treat bf as continuous to test for trend adjusted for age
          sumfit.conbf.j<-summary(glm(as.formula(paste(names(datlist)[j],paste(c(comvarnum,adjustvar),collapse="+"),sep="~")), data=alphamap,family="gaussian"))
          alphasum[j,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<-sumfit.conbf.j$coefficients[2,]
        }
        if (nlevcom==2){
          alphasum[j,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(sumfit.j$coefficients[2,],sumfit.j$coefficients[3,])
        }
      }
    }
  if (standardize==TRUE){
    return(list(alphamean=alphamean,alphamean.standardized=alphameans,alphasum=alphasum))
  }
  if (standardize==FALSE){
    return(list(alphamean=alphamean,alphasum=alphasum))
  }
}


# Filter taxonomies or pathways using prevalence and abundance threshold
#author: Nhan Ho (August 2017)
taxa.filter<-function(taxtab, percent.filter=0.05, relabund.filter=0.00005){
  # filter (remove) taxa with relative abundance <relabund.filter and available in <percent.filter of number of samples
  taxlev<-paste("l",2:(length(taxtab)+1),sep="")
  taxlistf<-list()
  for (j in 1:length(taxlev)){
    taxdat<-as.data.frame(taxtab[[j]])
    # get assigned taxa only
    taxlist<-colnames(taxdat)[grep("k__",colnames(taxdat))]
    #filter using percent.filter
    taxtest<-apply(taxdat[,taxlist],2,function(x){length(x[!is.na(x)&x>0])})
    taxget<-taxtest[taxtest>=percent.filter*(nrow(taxdat))]
    #filter using relabund.filter
    taxtestm<-apply(taxdat[,taxlist],2,mean,na.rm=T)
    taxgetm<-taxtestm[taxtestm>relabund.filter]
    taxlistf[[j]]<-c(names(taxget)[names(taxget) %in% names(taxgetm)])
  }
  names(taxlistf)<-taxlev
  return(taxlistf)
}


#compare taxa summary tables at all levels for relative abundance using different methods
#author: Nhan Ho (June 2017, add transformation June 2018)
taxa.compare<-function(taxtab,taxsum="rel",propmed.rel="gamlss",comvar="bf",adjustvar="age.sample",longitudinal="yes",p.adjust.method="fdr",percent.filter=0.05,relabund.filter=0.00005,pooldata=FALSE,max.lev=6,...){
  #propmed.rel can choose "lm" or "gamlss" this is only applicable for relative abundance
  #apply to taxa summary table already merged to mapping file
  #max.lev=6 (genus), or 7 (species)
  #comvar need to be a factor
  sapply(c("lme4","sjmisc", "sjPlot", "lmerTest","glmmADMB", "pscl", "MASS", "boot","betareg", "gamlss","gdata","ZIBR","zCompositions","compositions"), require, character.only = TRUE) 
  taxlev<-paste("l",2:(length(taxtab)+1),sep="")
  estisum<-list()
  for (j in 1:length(taxlev)){
    print(j)
    taxdat<-as.data.frame(taxtab[[j]])
    taxdat[,comvar]<-drop.levels(taxdat[,comvar],reorder=FALSE) #drop missing/unused level and keep level order
    taxdat[,"comvarnum"]<-as.numeric(taxdat[,comvar]) # for trend testing
    comvarnum<-"comvarnum"
    levcom<-levels(taxdat[,comvar])
    nlevcom<-nlevels(as.factor(as.character(taxdat[,comvar]))) # to remove empty level
    # get assigned taxa only
    taxlist<-colnames(taxdat)[grep("k__",colnames(taxdat))]
    #filter using percent.filter
    taxtest<-apply(taxdat[,taxlist],2,function(x){length(x[!is.na(x)&x>0])})
    taxget<-taxtest[taxtest>=percent.filter*(nrow(taxdat))]
    #taxname<-names(taxget)
    #filter using relabund.filter
    taxtestm<-apply(taxdat[,taxlist],2,mean,na.rm=T)
    taxgetm<-taxtestm[taxtestm>relabund.filter]
    taxname<-names(taxget)[names(taxget) %in% names(taxgetm)]
    
    #transformation of relative abundance
    if (propmed.rel=="gamlss" &transform!="none"){
      stop("gamlss with beta zero-inflated family should only be used for relative abundance without transformation")
    }
    if (transform!="clr" &zeroreplace.method!="none"){
      stop("Zero replacement is only implemented for use with CLR transformation")
    }
    if (transform=="clr" &zeroreplace.method=="none"){
      stop("Zero replacement needs to be done before CLR transformation")
    }
    if (propmed.rel=="lm" &transform=="asin.sqrt"){
      asintransform <- function(p) { asin(sqrt(p)) }
      taxdat[,taxname]<-apply(taxdat[,taxname],2,asintransform)
    }
    if (propmed.rel=="lm" &transform=="logit"){
      logittransform <- function(p) { log(p/(1-p)) }
      taxdat[,taxname]<-apply(taxdat[,taxname],2,logittransform )
    }
    if (propmed.rel=="lm" &transform=="clr"){
      #zero replacement using package zCompositions
      if (zeroreplace.method=="multLN"){
        test0<-zCompositions::multLN(taxdat[,taxname],label=0,dl=rep(1,length(taxname)))
      }
      if (zeroreplace.method=="multKM"){
        test0<-zCompositions::multKM(taxdat[,taxname],label=0,dl=rep(1,length(taxname)))
      }
      if (zeroreplace.method=="multRepl"){
        test0<-zCompositions::multRepl(taxdat[,taxname],label=0,dl=rep(1,length(taxname)))
      }
      if (zeroreplace.method=="lrEM"){
        test0<-zCompositions::lrEM(taxdat[,taxname],label=0,dl=rep(1,length(taxname)))
      }
      if (zeroreplace.method=="lrDA"){
        test0<-zCompositions::lrDA(taxdat[,taxname],label=0,dl=rep(1,length(taxname)))
      }
      #CLR transformation of imputed data using package compositions
      clrdat<-as.data.frame(clr(test0))
      taxdat[,taxname]<-clrdat
    }
    estisum[[j]]<-matrix(NA,nrow=length(taxname),ncol=20)
    colnames(estisum[[j]])<-c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","pval.adjust.nebf",
                              "estimate.nbf","se.nbf","teststat.nbf","pval.nbf","pval.adjust.nbf",
                              "estimate.age","se.age","teststat.age","pval.age","pval.adjust.age",
                              "estimate.conbf","se.conbf","teststat.conbf","pval.conbf","pval.adjust.conbf")
    rownames(estisum[[j]])<-taxname
    for (i in 1: length(taxname)){
      print(i)
        if (longitudinal=="yes"){
          #linear mixed model: not optimal test but work well
          if (propmed.rel=="lm"){
            fitsum.ji<-try(summary(glmer(as.formula(paste(taxname[i],paste(c(comvar,adjustvar,"(1|personid)"),collapse="+"),sep="~")), data=taxdat,family=gaussian(link="identity"))))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","estimate.nbf","se.nbf","teststat.nbf","estimate.age","se.age","teststat.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,],fitsum.ji$coefficients[4,])
                #calculate pval
                z.nebf<-estisum[[j]][i,"estimate.nebf"]/estisum[[j]][i,"se.nebf"]
                estisum[[j]][i,"pval.nebf"]<- 2*pnorm(-abs(z.nebf))
                z.nbf<-estisum[[j]][i,"estimate.nbf"]/estisum[[j]][i,"se.nbf"]
                estisum[[j]][i,"pval.nbf"]<- 2*pnorm(-abs(z.nbf))
                z.age<-estisum[[j]][i,"estimate.age"]/estisum[[j]][i,"se.age"]
                estisum[[j]][i,"pval.age"]<- 2*pnorm(-abs(z.age))
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(glmer(as.formula(paste(taxname[i],paste(c(comvarnum,adjustvar,"(1|personid)"),collapse="+"),sep="~")), data=taxdat,family=gaussian(link="identity")))
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf")]<-fitsum.conbf.ji$coefficients[2,]
                z.conbf<-estisum[[j]][i,"estimate.conbf"]/estisum[[j]][i,"se.conbf"]
                estisum[[j]][i,"pval.conbf"]<- 2*pnorm(-abs(z.conbf))
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","estimate.age","se.age","teststat.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,])
                #calculate pval
                z.nebf<-estisum[[j]][i,"estimate.nebf"]/estisum[[j]][i,"se.nebf"]
                estisum[[j]][i,"pval.nebf"]<- 2*pnorm(-abs(z.nebf))
                z.age<-estisum[[j]][i,"estimate.age"]/estisum[[j]][i,"se.age"]
                estisum[[j]][i,"pval.age"]<- 2*pnorm(-abs(z.age))
              }
            }
          }
          #Generalized Additive Models for Location Scale and Shape: Betazeroinflated family, mu link logit
          if (propmed.rel=="gamlss"){
            testdat<-taxdat[,c(taxname[i],comvar,comvarnum,adjustvar,"personid")]
            if (nlevcom==2){
              testdat<-taxdat[,c(taxname[i],comvar,adjustvar,"personid")]
            }
            testdat[,taxname[i]][testdat[,taxname[i]]==1]<-0.9999 # dirty fix for 1 value of relative abundance in UW data (to be checked)
            testdat<-na.omit(testdat)
            if (nrow(testdat[is.na(testdat[,comvar]),])>0){
              testdat<-testdat[!is.na(testdat[,comvar]),] #dirty fix for missing values of bf in usbmk data (to be checked)
              testdat<-testdat[!is.na(testdat[,adjustvar]),] #to be checked
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.character)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.factor)
              testdat[,comvar]<-factor(testdat[,comvar],levels=levcom)
            }
            #for pooled analysis, only run model on complete case data
            if (pooldata==TRUE){
              testdat<-na.omit(testdat)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.character)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.factor)
              testdat[,comvar]<-factor(testdat[,comvar],levels=levcom)
            }
            # error if include covarnum with NA values=> dirty fix for testdat
            fitsum.ji<-try(summary(gamlss(as.formula(paste(taxname[i],paste(c(comvar,adjustvar,"random(personid)"),collapse="+"),sep="~")), family = BEZI, data = testdat[,c(taxname[i],comvar,adjustvar,"personid")], trace = FALSE),save=TRUE))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
              estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,],fitsum.ji$coef.table[4,])
              #treat bf as continuous to test for trend
              fitsum.conbf.ji<-summary(gamlss(as.formula(paste(taxname[i],paste(c(comvarnum,adjustvar,"random(personid)"),collapse="+"),sep="~")), family = BEZI, data = testdat, trace = FALSE),save=TRUE)
              estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<- fitsum.conbf.ji$coef.table[2,]
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,])
              }
            }
          }
        }
        if (longitudinal=="no"){
          #linear regression: not optimal test but work
          if (propmed.rel=="lm"){
            fitsum.ji<-try(summary(glm(as.formula(paste(taxname[i],paste(c(comvar,adjustvar),collapse="+"),sep="~")), data=taxdat,family="gaussian")))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,],fitsum.ji$coefficients[4,])
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(glm(as.formula(paste(taxname[i],paste(c(comvarnum,adjustvar),collapse="+"),sep="~")), data=taxdat,family="gaussian"))
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<- fitsum.conbf.ji$coefficients[2,]
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,])
              }
            }
          }
          #Generalized Additive Models for Location Scale and Shape: Betazeroinflated family, mu link logit
          if (propmed.rel=="gamlss"){
            testdat<-taxdat[,c(taxname[i],comvar,comvarnum,adjustvar)]
            if (nlevcom==2){
              testdat<-taxdat[,c(taxname[i],comvar,adjustvar)]
            }
            testdat[,taxname[i]][testdat[,taxname[i]]==1]<-0.9999 # dirty fix for 1 value of relative abundance in UW data (to be checked)
            testdat<-na.omit(testdat)
            #testdat<-testdat[!is.na(testdat[,comvar]),] #dirty fix for missing values of bf in usbmk data (to be checked)
            #testdat<-testdat[!is.na(testdat[,adjustvar]),] #to be checked
            # error if include comvarnum with NA values => dirty fix for testdat
            fitsum.ji<-try(summary(gamlss(as.formula(paste(taxname[i],paste(c(comvar,adjustvar),collapse="+"),sep="~")), family = BEZI, data = testdat[,c(taxname[i],comvar,adjustvar)], trace = FALSE),save=TRUE))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,],fitsum.ji$coef.table[4,])
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(gamlss(as.formula(paste(taxname[i],paste(c(comvarnum,adjustvar),collapse="+"),sep="~")), family = BEZI, data = testdat, trace = FALSE),save=TRUE)
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<- fitsum.conbf.ji$coef.table[2,]
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,])
              }
            }
          }
        }
    }
    estisum[[j]][,c("pval.adjust.nebf","pval.adjust.nbf","pval.adjust.age","pval.adjust.conbf")]<-apply(estisum[[j]][,c("pval.nebf","pval.nbf","pval.age","pval.conbf")],2, p.adjust, method = p.adjust.method)
    estisum[[j]]<-estisum[[j]][order(estisum[[j]][,"pval.nebf"]),]
  }
  names(estisum)<-taxlev
  return(estisum)
}

# taxa summary for mean, sd, number of subjects by age in months rounded
# Author: Nhan Ho (July, 2017)
taxa.meansdn<-function(taxtab, sumvar="bf", groupvar="age.sample",percent.filter=0.05,othervar="none"){
  # taxtab must be specified: bf as factor variable for breastfeeding status, age.sample for infant age at sample collection
  #max.lev=6 (genus), or 7 (species) ,max.lev=6
  sapply(c("reshape2","dplyr"), require, character.only = TRUE)
  taxlev<-paste("l",2:(length(taxtab)+1),sep="")
  estisum<-list()
  for (j in 1:length(taxlev)){
    print(j)
    taxdat<-as.data.frame(taxtab[[j]])
    #taxdat<-taxdat %>% rowwise %>% ungroup # ungroup dplyr grouped data
    taxdat$sumvar<-taxdat[,sumvar]
    taxdat$groupvar<-taxdat[,groupvar]
    # get assigned taxa only
    if (othervar!="none"){
      taxlist<-colnames(taxdat)[!colnames(taxdat) %in% othervar]
    }
    if (othervar=="none") {
      taxlist<-colnames(taxdat)[grep("k__",colnames(taxdat))]
    }
    #filter using percent.filter
    taxtest<-apply(taxdat[,taxlist],2,function(x){length(x[!is.na(x)&x>0])})
    taxget<-taxtest[taxtest>=percent.filter*(nrow(taxdat))]
    taxname<-names(taxget)
    sumdat<-taxdat[,c("sumvar", "groupvar",taxname)]
    sumdat[,taxname]<-lapply(sumdat[,taxname],as.character)
    sumdat[,taxname]<-lapply(sumdat[,taxname],as.numeric)
    sumdat<-sumdat[!is.na(sumdat[,"sumvar"]),]
    if (groupvar=="age.sample"){
      estisum[[j]]<-sumdat %>%
      mutate(groupvar=as.factor(as.character(round(as.numeric(as.character(groupvar)),0)))) %>%
      group_by(sumvar, groupvar) %>%
      #summarise_each(funs(mean(.), sd(.), n())) #, na.rm = TRUE , na.rm = TRUE
        # In the dplyr 0.7.4, summarise_each(and mutate_each) is already deprecated, so we cannot use these functions.
        summarise_all(funs(mean(.), sd(.), n()))
      estisum[[j]]<-estisum[[j]]%>%
      mutate(groupvar=as.numeric(as.character(groupvar))) %>%
      arrange(sumvar,groupvar)
      estisum[[j]]<-na.omit(estisum[[j]])
      }
      else {
        estisum[[j]]<-sumdat %>% group_by(sumvar, groupvar) %>%
          #summarise_each(funs(mean(.), sd(.), n())) #, na.rm = TRUE, na.rm = TRUE
          # In the dplyr 0.7.4, summarise_each(and mutate_each) is already deprecated, so we cannot use these functions.
          summarise_all(funs(mean(.), sd(.), n()))
      }
    colnames(estisum[[j]])[colnames(estisum[[j]]) %in% c("sumvar","groupvar")]<-c(sumvar,groupvar)
    }
    names(estisum)<-taxlev
  return(estisum)
}



# Function to do meta-analysis on taxa abundance estimate and store results
# author: Nhan Ho (July, 2017)
# to adjust : effect.measure => sm=effect.measure; backtranform=FALSE => backtransf=backtranform; remove the argument (if sm==)
meta.taxa<-function(taxcomdat, sm="RR",p.adjust.method="fdr",percent.meta=0.5,pool.var="taxa",...){
  # put all taxa relative abundance estimate table of a given level from all studies in a list
  # sm=c("RR","RD") # RR for gamlss and RD for glmer # to get RR and 95%CI, need to exponentiate the estimate and ci
  # effect.type =c("nebf", "nbf","conbf", "age")
  # metamod=c("fixed","random") ,max.lev=6
  sapply(c("meta","metafor","rmeta"), require, character.only = TRUE)
  #taxlev<-paste("l",2:length(taxcomdat),sep="")
  taxlev<-names(taxcomdat)
  metatab.f<-list()
  metatab.r<-list()
  for (i in 1: length(taxlev)){
    print(i)
    taxdat<-taxcomdat[[i]]
    #taxname<-unique(taxdat[,"taxa"])
    taxname<-unique(taxdat[,pool.var])
    metatab.f[[i]]<-matrix(NA,ncol=28, nrow=length(taxname))
    colnames(metatab.f[[i]])<-c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf',
                                "estimate.nbf",'se.nbf','ll.nbf','ul.nbf','z.nbf','p.nbf','p.adjust.nbf',
                                "estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age',
                                "estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf')
    rownames(metatab.f[[i]])<-taxname
    metatab.r[[i]]<-matrix(NA,ncol=28, nrow=length(taxname))
    colnames(metatab.r[[i]])<-c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf',
                                "estimate.nbf",'se.nbf','ll.nbf','ul.nbf','z.nbf','p.nbf','p.adjust.nbf',
                                "estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age',
                                "estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf')
    rownames(metatab.r[[i]])<-taxname
    for (j in 1:length(taxname)){
      print(j)
      if (sm=="RR"){
        #testdat<-subset(taxdat,pool.var %in% taxname[j])
        testdat<-taxdat[taxdat[,pool.var] %in% taxname[j],]
        # do metanalysis only for taxa exist in >=percent.meta of studies
        if (nrow(testdat)<percent.meta*(length(unique(taxdat$author)))){
          metatab.f[[i]][j,]<- rep(NA,ncol(metatab.f[[i]]))
          metatab.r[[i]][j,]<- rep(NA,ncol(metatab.r[[i]]))
        }
        if (nrow(testdat)>=percent.meta*(length(unique(taxdat$author)))){
          fit.nebf<-metagen(estimate.nebf, se.nebf, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RR", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf')]<-c(summary(fit.nebf)$fixed$TE,summary(fit.nebf)$fixed$seTE,summary(fit.nebf)$fixed$lower,summary(fit.nebf)$fixed$upper,summary(fit.nebf)$fixed$z,summary(fit.nebf)$fixed$p)
          metatab.r[[i]][j,c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf')]<-c(summary(fit.nebf)$random$TE,summary(fit.nebf)$random$seTE,summary(fit.nebf)$random$lower,summary(fit.nebf)$random$upper,summary(fit.nebf)$random$z,summary(fit.nebf)$random$p)
          fit.nbf<-metagen(estimate.nbf, se.nbf, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RR", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.nbf",'se.nbf','ll.nbf','ul.nbf','z.nbf','p.nbf')]<-c(summary(fit.nbf)$fixed$TE,summary(fit.nbf)$fixed$seTE,summary(fit.nbf)$fixed$lower,summary(fit.nbf)$fixed$upper,summary(fit.nbf)$fixed$z,summary(fit.nbf)$fixed$p)
          metatab.r[[i]][j,c("estimate.nbf",'se.nbf','ll.nbf','ul.nbf','z.nbf','p.nbf')]<-c(summary(fit.nbf)$random$TE,summary(fit.nbf)$random$seTE,summary(fit.nbf)$random$lower,summary(fit.nbf)$random$upper,summary(fit.nbf)$random$z,summary(fit.nbf)$random$p)
          fit.age<-metagen(estimate.age, se.age, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RR", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age')]<-c(summary(fit.age)$fixed$TE,summary(fit.age)$fixed$seTE,summary(fit.age)$fixed$lower,summary(fit.age)$fixed$upper,summary(fit.age)$fixed$z,summary(fit.age)$fixed$p)
          metatab.r[[i]][j,c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age')]<-c(summary(fit.age)$random$TE,summary(fit.age)$random$seTE,summary(fit.age)$random$lower,summary(fit.age)$random$upper,summary(fit.age)$random$z,summary(fit.age)$random$p)
          fit.conbf<-metagen(estimate.conbf, se.conbf, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RR", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf')]<-c(summary(fit.conbf)$fixed$TE,summary(fit.conbf)$fixed$seTE,summary(fit.conbf)$fixed$lower,summary(fit.conbf)$fixed$upper,summary(fit.conbf)$fixed$z,summary(fit.conbf)$fixed$p)
          metatab.r[[i]][j,c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf')]<-c(summary(fit.conbf)$random$TE,summary(fit.conbf)$random$seTE,summary(fit.conbf)$random$lower,summary(fit.conbf)$random$upper,summary(fit.conbf)$random$z,summary(fit.conbf)$random$p)
        }
      }
      if (sm=="RD"){
        #testdat<-subset(taxdat,pool.var %in% taxname[j])
        testdat<-taxdat[taxdat[,pool.var] %in% taxname[j],]
        # do metanalysis only for taxa exist in >=percent.meta of studies
        if (nrow(testdat)<percent.meta*(length(unique(taxdat$author)))){
          metatab.f[[i]][j,]<- rep(NA,ncol(metatab.f[[i]]))
          metatab.r[[i]][j,]<- rep(NA,ncol(metatab.f[[i]]))
        }
        if (nrow(testdat)>=percent.meta*(length(unique(taxdat$author)))){
          fit.nebf<-metagen(estimate.nebf, se.nebf, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RD", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf')]<-c(summary(fit.nebf)$fixed$TE,summary(fit.nebf)$fixed$seTE,summary(fit.nebf)$fixed$lower,summary(fit.nebf)$fixed$upper,summary(fit.nebf)$fixed$z,summary(fit.nebf)$fixed$p)
          metatab.r[[i]][j,c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf')]<-c(summary(fit.nebf)$random$TE,summary(fit.nebf)$random$seTE,summary(fit.nebf)$random$lower,summary(fit.nebf)$random$upper,summary(fit.nebf)$random$z,summary(fit.nebf)$random$p)
          fit.nbf<-metagen(estimate.nbf, se.nbf, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RD", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.nbf",'se.nbf','ll.nbf','ul.nbf','z.nbf','p.nbf')]<-c(summary(fit.nbf)$fixed$TE,summary(fit.nbf)$fixed$seTE,summary(fit.nbf)$fixed$lower,summary(fit.nbf)$fixed$upper,summary(fit.nbf)$fixed$z,summary(fit.nbf)$fixed$p)
          metatab.r[[i]][j,c("estimate.nbf",'se.nbf','ll.nbf','ul.nbf','z.nbf','p.nbf')]<-c(summary(fit.nbf)$random$TE,summary(fit.nbf)$random$seTE,summary(fit.nbf)$random$lower,summary(fit.nbf)$random$upper,summary(fit.nbf)$random$z,summary(fit.nbf)$random$p)
          fit.age<-metagen(estimate.age, se.age, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RD", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age')]<-c(summary(fit.age)$fixed$TE,summary(fit.age)$fixed$seTE,summary(fit.age)$fixed$lower,summary(fit.age)$fixed$upper,summary(fit.age)$fixed$z,summary(fit.age)$fixed$p)
          metatab.r[[i]][j,c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age')]<-c(summary(fit.age)$random$TE,summary(fit.age)$random$seTE,summary(fit.age)$random$lower,summary(fit.age)$random$upper,summary(fit.age)$random$z,summary(fit.age)$random$p)
          fit.conbf<-metagen(estimate.conbf, se.conbf, studlab=paste(author,year,"(",pop,")"),data=testdat,sm="RD", backtransf=FALSE)
          metatab.f[[i]][j,c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf')]<-c(summary(fit.conbf)$fixed$TE,summary(fit.conbf)$fixed$seTE,summary(fit.conbf)$fixed$lower,summary(fit.conbf)$fixed$upper,summary(fit.conbf)$fixed$z,summary(fit.conbf)$fixed$p)
          metatab.r[[i]][j,c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf')]<-c(summary(fit.conbf)$random$TE,summary(fit.conbf)$random$seTE,summary(fit.conbf)$random$lower,summary(fit.conbf)$random$upper,summary(fit.conbf)$random$z,summary(fit.conbf)$random$p)
        }
      }
    }
    metatab.f[[i]][!is.na(metatab.f[[i]][,"estimate.nebf"]),c("p.adjust.nebf","p.adjust.nbf","p.adjust.age","p.adjust.conbf")]<-apply(metatab.f[[i]][!is.na(metatab.f[[i]][,"estimate.nebf"]),c("p.nebf","p.nbf","p.age","p.conbf")],2, p.adjust, method = p.adjust.method)
    metatab.f[[i]]<-metatab.f[[i]][order(metatab.f[[i]][,"p.nebf"]),]
    metatab.r[[i]][!is.na(metatab.r[[i]][,"estimate.nebf"]),c("p.adjust.nebf","p.adjust.nbf","p.adjust.age","p.adjust.conbf")]<-apply(metatab.r[[i]][!is.na(metatab.r[[i]][,"estimate.nebf"]),c("p.nebf","p.nbf","p.age","p.conbf")],2, p.adjust, method = p.adjust.method)
    metatab.r[[i]]<-metatab.r[[i]][order(metatab.r[[i]][,"p.nebf"]),]
  }
  names(metatab.f)<-names(metatab.r)<-taxlev
  metatab.fr<-list(metatab.f,metatab.r)
  names(metatab.fr)<-c("fixed","random")
  return(metatab.fr)
}



# plot mean taxa abundance by groups
# author: Nhan Ho (August 2017)
taxa.mean.plot<-function(tabmean,sumvar="taxa",tax.select="none",taxlist="none",tax.lev="l2", comvar, groupvar,mean.filter=0.005, pallete.by.phylum=FALSE, show.taxname="full",legend.position="right",xlab="Chronological age (month)",ylab="Relative abundance"){
  #show.taxname="full" or "short"
  sapply(c("ggplot2","reshape2","RColorBrewer","plyr"), require, character.only = TRUE)
  tab<-tabmean[[tax.lev]]
  taxname<-c(colnames(tab)[grep("mean",colnames(tab))])
  tabm<-apply(tab[,taxname],2,mean)
  tabm<-tabm[tabm>=mean.filter]
  taxl<-paste(taxlist[[tax.lev]],"_mean",sep="")
  taxuse<-taxname[taxname %in% taxl]
  if (tax.lev=="l2"){
      taxuse<-taxuse
    }
    if (tax.lev=="l7"){
      stringt<-"s__"
      taxuse<-taxuse[grep(".s__",taxuse)]
      #taxs<-sub(".*s__", "",taxuse)
      #taxuse<-taxuse[!taxs %in% "_mean"]
    }
    if (tax.lev=="l6"){
      stringt<-"g__"
      taxuse<-taxuse[grep(".g__",taxuse)]
      #taxs<-sub(".*g__", "",taxuse)
      #taxuse<-taxuse[!taxs %in% "_mean"]
    }
    if (tax.lev=="l5"){
      stringt<-"f__"
      taxuse<-taxuse[grep(".f__",taxuse)]
      taxs<-sub(".*f__", "",taxuse)
      taxuse<-taxuse[!taxs %in% "_mean"]
    }
    if (tax.lev=="l4"){
      stringt<-"o__"
      taxuse<-taxuse[grep(".o__",taxuse)]
      taxs<-sub(".*o__", "",taxuse)
      taxuse<-taxuse[!taxs %in% "_mean"]
    }
  if (tax.select=="none"){
    taxuse<-taxuse[taxuse %in% names(tabm)]
  }
  if (tax.select!="none"){
    taxuse<-taxuse[taxuse %in% paste(tax.select,"_mean",sep="")]
  }
  taxuse.rm<-gsub("_mean","",taxuse)
  tab[,"others_mean"]<-1-apply(tab[,taxuse],1,sum)
  tab.l <- reshape(tab,
                      varying = c("others_mean",taxuse),
                      v.names = "rel_abund",
                      timevar = "taxa",
                      times = c("others_mean",taxuse),
                      new.row.names = 1:(nrow(tab)*length(c("others_mean",taxuse))),
                      direction = "long")
  tab.l<-as.data.frame(tab.l)
  tab.l$taxa<-gsub("_mean","",tab.l$taxa)
  tab.l<-tab.l[,c(comvar,groupvar,"taxa","rel_abund")]
  tab.l$taxa<-gsub("k__bacteria.p__","",tab.l$taxa)
  tab.l$taxa<-as.factor(as.character(tab.l$taxa))
  tab.l$taxa<-factor(tab.l$taxa,levels=c(levels(tab.l$taxa)[!levels(tab.l$taxa) %in% "others"],"others"))
  tab.l$phylum<-sub(".c__.*","",tab.l$taxa)
  tab.l<-tab.l[order(tab.l$taxa),]
  if (tax.lev!="l2"){
    tab.l$taxas<-sub(paste(".*",stringt,sep=""), "",tab.l$taxa)
  }
  if (tax.lev=="l2"){
    tab.l$taxas<-tab.l$taxa
  }
  tab.l$taxas<-paste0(toupper(substr(as.character(tab.l$taxas), 1, 1)), substr(as.character(tab.l$taxas), 2, nchar(as.character(tab.l$taxas))))
  tab.l$taxas<-factor(tab.l$taxas,levels=unique(tab.l$taxas))
  #get color vector
  n <- nlevels(tab.l$taxa)
  qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
  col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
  tab.l$phylum<-factor(tab.l$phylum,levels=c(unique(tab.l$phylum)[!unique(tab.l$phylum) %in% "others"],"others"))
  if (pallete.by.phylum==TRUE){
  tab.l$colpal<-mapvalues(tab.l$phylum, from=c("actinobacteria","bacteroidetes","firmicutes","proteobacteria","others" ),to=c("Greens","Purples","Reds","Blues","Greys"))
  ngroup<-length(unique(tab.l[,comvar]))*length(unique(tab.l[,groupvar]))
  coltab<-(table(tab.l$colpal)/ngroup)
  colset<-list()
    for (i in 1: nlevels(tab.l$colpal)){
      colset[[i]]<-rev(brewer.pal(9,levels(tab.l$colpal)[i]))[1:coltab[i]]
    }
  tab.l$col<-mapvalues(tab.l$taxa,from=levels(tab.l$taxa),to=c(unlist(colset)))
  col_vector<-c(unlist(colset))
  }
  # display taxa names
  if(show.taxname=="short"){
    tab.l$taxa<-tab.l$taxas
  }
  if (groupvar=="age.sample"){
    #stacked plot by age
    p<-ggplot(tab.l, aes(x=get(as.character(groupvar)),y=rel_abund))+ geom_area(aes(fill=taxa))+
      scale_fill_manual(values=col_vector)+ xlab(xlab)+ylab(ylab)+
      labs(fill='')+
      theme(legend.position = legend.position)+
      theme(legend.text = element_text(colour="black", size = 10, face="bold"))+
      scale_x_continuous(breaks=seq(from=0,to=24,by=3),
                         labels=seq(from=0,to=24,by=3))+
      theme(legend.key.size = unit(0.5, "cm"),
            axis.line = element_line(colour = "black"),
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.border = element_blank(),
            panel.background = element_blank(),
            strip.background =element_rect(fill="white"),
            axis.text.y =element_text(size=10, colour = "black",face="bold"),
            axis.text.x =element_text(size=10,face="bold",colour="black"),
            axis.title=element_text(size=10,face="bold"),
            strip.text.x = element_text(size=10, face="bold"))+
      guides(fill=guide_legend(ncol=1)) +
      facet_wrap(~get(as.character(comvar)), ncol = 1)
      #facet_grid(get(as.character(comvar))~ .)
    }
  else{
    #barplot
    p<-ggplot(tab.l, aes(x = get(as.character(comvar)), y = rel_abund, fill = taxa)) +
      geom_bar(stat = "identity")+ scale_fill_manual(values=col_vector)+ xlab(comvar)+ylab(ylab)+
      labs(fill='')+ guides(fill=guide_legend(ncol=1))+
      theme(legend.text = element_text(colour="black", size = 10,face="bold"))+
      theme(legend.position = legend.position)+
      theme(legend.key.size = unit(0.5, "cm"),
            axis.line = element_line(colour = "black"),
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            panel.border = element_blank(),
            panel.background = element_blank(),
            strip.background =element_rect(fill="white"),
            axis.text.y =element_text(size=10, colour = "black",face="bold"),
            axis.text.x =element_text(size=10,face="bold",colour="black"),
            axis.title=element_text(size=10,face="bold"),
            strip.text.x = element_text(size=10, face="bold"))+
      guides(fill=guide_legend(ncol=1)) +
      facet_wrap(~get(as.character(groupvar)), ncol = 1)
      #facet_grid(get(as.character(groupvar))~ .)
    }
  return(list(p=p,taxuse.rm=taxuse.rm))
}



# show taxacom table
# author: Nhan Ho (August 2017)
taxcomtab.show<-function(taxcomtab, tax.lev="l2",tax.select="none",showvar=".nebf",readjust.p=FALSE,p.adjust.method="fdr",p.cutoff.type="pval",p.cutoff=0.05,digit=2,p.digit=4,...){
  test<-taxcomtab[[tax.lev]][,1:5]
  colnames(test)<-gsub(".nebf","",colnames(test))
  if (showvar==".age"){
    test<-taxcomtab[[tax.lev]][,colnames(taxcomtab[[tax.lev]])[grep(".age",colnames(taxcomtab[[tax.lev]]))]]
    colnames(test)<-gsub(".age","",colnames(test))
  }
  if (showvar==".conbf"){
    test<-taxcomtab[[tax.lev]][,colnames(taxcomtab[[tax.lev]])[grep(".conbf",colnames(taxcomtab[[tax.lev]]))]]
    colnames(test)<-gsub(".conbf","",colnames(test))
  }
  taxuse<-rownames(test)
  if (tax.lev=="l7"){
    taxuse<-rownames(test)[grep(".s__",rownames(test))]
  }
  if (tax.lev=="l6"){
    taxuse<-rownames(test)[grep(".g__",rownames(test))]
  }
  if (tax.lev=="l5"){
    taxuse<-rownames(test)[grep(".f__",rownames(test))]
  }
  if (tax.lev=="l4"){
    taxuse<-rownames(test)[grep(".o__",rownames(test))]
  }
  if (tax.select!="none"){
    taxuse<-taxuse[taxuse %in% tax.select]
  }
  datuse<-as.data.frame(test[taxuse,])
  if (readjust.p==TRUE){
    datuse[,"pval.adjust"]<-p.adjust(datuse[,"pval"], method = p.adjust.method)
  }
  rownames(datuse)<-gsub("k__bacteria.p__","",rownames(datuse))
  datuse<-as.data.frame(datuse)
  datsig<-datuse[datuse[,p.cutoff.type]<p.cutoff,]
  datsig<-datsig[order(datsig[,p.cutoff.type]),]
  datsig[,"ll"]<-datsig[,"estimate"]-1.96*datsig[,"se"]
  datsig[,"ul"]<-datsig[,"estimate"]+1.96*datsig[,"se"]
  datsig[,c("estimate","ll","ul")]<-round(datsig[,c("estimate","ll","ul")],digit)
  datsig[,c("pval","pval.adjust")]<-round(datsig[,c("pval","pval.adjust")],p.digit)
  return(datsig)
}



# display meta-analysis results of taxa relative abundance
#author: Nhan Ho (Aug 2017)
metatab.show<-function(metatab,taxacom.pooled.tab,sumvar="taxa",tax.lev="l2",showvar=".nebf",readjust.p=FALSE,p.cutoff.type="p", p.cutoff=0.05,display="plot",plot="heatmap",fill.value="log(OR)",grid=FALSE,digit=2,p.digit=4){
  #p.cutoff.type=c("p","p.adjust")
  #display=c("plot","table","data")
  #plot=c("heatmap","forest")
  #showvar=c(".nebf",".age",".conbf")
  #sumvar=c("taxa","path")
  #readjust.p: whether or not re-calculate adjusted p-values based on the number of p-values for specific level. default is FALSE.
  require(ggplot2);require(plyr)
  mtaba<-as.data.frame(metatab[[tax.lev]])
  #remove row with NA values (no meta-analysis)
  mtaba<-mtaba[!is.na(mtaba[,"estimate.nebf"]),]
  mtaba$taxa<-rownames(mtaba)
  if (showvar==".nebf"){
    if (sumvar=="taxa"){
      if (tax.lev=="l2"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("p__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.nebf"]<-p.adjust(mtab[,"p.nebf"],method="fdr")
        }
        taxsig<-mtab[mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf','taxa')]
      }
      if (tax.lev=="l4"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("o__",mtaba$taxa)]),]
        #mtab<-mtab[!is.na(mtab$estimate.nebf),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.nebf"]<-p.adjust(mtab[,"p.nebf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("o__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf','taxa')]
      }
      if (tax.lev=="l5"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("f__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.nebf"]<-p.adjust(mtab[,"p.nebf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("f__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf','taxa')]
      }
      if (tax.lev=="l6"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("g__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.nebf"]<-p.adjust(mtab[,"p.nebf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("g__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf','taxa')]
      }
      if (tax.lev=="l7"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("s__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.nebf"]<-p.adjust(mtab[,"p.nebf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("s__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf','taxa')]
      }
    }
    if (sumvar=="path"){
      mtab<-mtaba[!is.na(mtaba$estimate.nebf),]
      if (readjust.p==TRUE){
        mtab[,"p.adjust.nebf"]<-p.adjust(mtab[,"p.nebf"],method="fdr")
      }
      taxsig<-mtab[mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.nebf",'se.nebf','ll.nebf','ul.nebf','z.nebf','p.nebf','p.adjust.nebf','taxa')]
    }
    if (nrow(taxsig)>0){
    taxsig$study<-"Pooled estimate"
    #taxsig<-taxsig[order(taxsig$estimate.nebf),]
    taxsig<-taxsig[order(taxsig$taxa,decreasing = TRUE),]
    taxname.sig<-rownames(taxsig)
    taxname.sig.s<-gsub('k__bacteria.p__','',taxname.sig)
    taxsig$taxa<-gsub('k__bacteria.p__','',taxsig$taxa)
    taxsig$taxa<-factor(taxsig$taxa,levels=c(taxname.sig.s))
    pooltab<-taxacom.pooled.tab[[tax.lev]]
    if(sumvar=="path"){
      pooltab$taxa<-pooltab$path
    }
    taxsig.stud<-pooltab[pooltab$taxa %in% rownames(taxsig),c("estimate.nebf",'taxa',"author","year","pop")]
    taxsig.stud$study<-paste(taxsig.stud$author,taxsig.stud$year,'(',taxsig.stud$pop,')',sep=' ')
    taxsig.all<-rbind.fill(taxsig.stud,taxsig)
    taxsig.all$taxa<-gsub('k__bacteria.p__','',taxsig.all$taxa)
    taxsig.all$taxa<-factor(taxsig.all$taxa, levels=taxname.sig.s)
    taxsig.all$study<-factor(taxsig.all$study, levels=c(unique(taxsig.stud$study),"Pooled estimate"))
    taxsig.all$estimate<-taxsig.all$estimate.nebf
    taxsig$estimate<-taxsig$estimate.nebf
    taxsig$ll<-taxsig$ll.nebf
    taxsig$ul<-taxsig$ul.nebf
    rownames(taxsig.all)<-NULL
    }
  }
  if (showvar==".age"){
    if (sumvar=="taxa"){
      if (tax.lev=="l2"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("p__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.age"]<-p.adjust(mtab[,"p.age"],method="fdr")
        }
        taxsig<-mtab[mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age','taxa')]
      }
      if (tax.lev=="l4"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("o__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.age"]<-p.adjust(mtab[,"p.age"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("o__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age','taxa')]
      }
      if (tax.lev=="l5"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("f__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.age"]<-p.adjust(mtab[,"p.age"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("f__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age','taxa')]
      }
      if (tax.lev=="l6"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("g__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.age"]<-p.adjust(mtab[,"p.age"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("g__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age','taxa')]
      }
      if (tax.lev=="l7"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("s__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.age"]<-p.adjust(mtab[,"p.age"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("s__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age','taxa')]
      }
    }
    if (sumvar=="path"){
      mtab<-mtaba[!is.na(mtaba$estimate.age),]
      if (readjust.p==TRUE){
        mtab[,"p.adjust.age"]<-p.adjust(mtab[,"p.age"],method="fdr")
      }
      taxsig<-mtab[mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.age",'se.age','ll.age','ul.age','z.age','p.age','p.adjust.age','taxa')]
    }
    if (nrow(taxsig)>0){
      taxsig$study<-"Pooled estimate"
      #taxsig<-taxsig[order(taxsig$estimate.age),]
      taxsig<-taxsig[order(taxsig$taxa,decreasing = TRUE),]
      taxname.sig<-rownames(taxsig)
      taxname.sig.s<-gsub('k__bacteria.p__','',taxname.sig)
      taxsig$taxa<-gsub('k__bacteria.p__','',taxsig$taxa)
      taxsig$taxa<-factor(taxsig$taxa,levels=c(taxname.sig.s))
      pooltab<-taxacom.pooled.tab[[tax.lev]]
      if(sumvar=="path"){
        pooltab$taxa<-pooltab$path
      }
      taxsig.stud<-pooltab[pooltab$taxa %in% rownames(taxsig),c("estimate.age",'taxa',"author","year","pop")]
      taxsig.stud$study<-paste(taxsig.stud$author,taxsig.stud$year,'(',taxsig.stud$pop,')',sep=' ')
      taxsig.all<-rbind.fill(taxsig.stud,taxsig)
      taxsig.all$taxa<-gsub('k__bacteria.p__','',taxsig.all$taxa)
      taxsig.all$taxa<-factor(taxsig.all$taxa, levels=taxname.sig.s)
      taxsig.all$study<-factor(taxsig.all$study, levels=c(unique(taxsig.stud$study),"Pooled estimate"))
      taxsig.all$estimate<-taxsig.all$estimate.age
      taxsig$estimate<-taxsig$estimate.age
      taxsig$ll<-taxsig$ll.age
      taxsig$ul<-taxsig$ul.age
      rownames(taxsig.all)<-NULL
    }
  }
  if (showvar==".conbf"){
    if (sumvar=="taxa"){
      if (tax.lev=="l2"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("p__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.conbf"]<-p.adjust(mtab[,"p.conbf"],method="fdr")
        }
        taxsig<-mtab[mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf','taxa')]
      }
      if (tax.lev=="l4"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("o__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.conbf"]<-p.adjust(mtab[,"p.conbf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("o__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf','taxa')]
      }
      if (tax.lev=="l5"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("f__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.conbf"]<-p.adjust(mtab[,"p.conbf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("f__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf','taxa')]
      }
      if (tax.lev=="l6"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("g__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.conbf"]<-p.adjust(mtab[,"p.conbf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("g__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf','taxa')]
      }
      if (tax.lev=="l7"){
        mtab<-mtaba[(mtaba$taxa %in% mtaba$taxa[grep("s__",mtaba$taxa)]),]
        if (readjust.p==TRUE){
          mtab[,"p.adjust.conbf"]<-p.adjust(mtab[,"p.conbf"],method="fdr")
        }
        taxsig<-mtab[(mtab$taxa %in% mtab$taxa[grep("s__",mtab$taxa)]) &mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf','taxa')]
      }
    }
    if (sumvar=="path"){
      mtab<-mtaba[!is.na(mtaba$estimate.conbf),]
      if (readjust.p==TRUE){
        mtab[,"p.adjust.conbf"]<-p.adjust(mtab[,"p.conbf"],method="fdr")
      }
      taxsig<-mtab[mtab[,paste(p.cutoff.type,showvar,sep="")]<=p.cutoff& !is.na(mtab[,paste(p.cutoff.type,showvar,sep="")]),c("estimate.conbf",'se.conbf','ll.conbf','ul.conbf','z.conbf','p.conbf','p.adjust.conbf','taxa')]
    }
    if (nrow(taxsig)>0){
      taxsig$study<-"Pooled estimate"
    #taxsig<-taxsig[order(taxsig$estimate.conbf),]
    taxsig<-taxsig[order(taxsig$taxa,decreasing = TRUE),]
    taxname.sig<-rownames(taxsig)
    taxname.sig.s<-gsub('k__bacteria.p__','',taxname.sig)
    taxsig$taxa<-gsub('k__bacteria.p__','',taxsig$taxa)
    taxsig$taxa<-factor(taxsig$taxa,levels=c(taxname.sig.s))
    pooltab<-taxacom.pooled.tab[[tax.lev]]
    if(sumvar=="path"){
      pooltab$taxa<-pooltab$path
    }
    taxsig.stud<-pooltab[pooltab$taxa %in% rownames(taxsig),c("estimate.conbf",'taxa',"author","year","pop")]
    taxsig.stud$study<-paste(taxsig.stud$author,taxsig.stud$year,'(',taxsig.stud$pop,')',sep=' ')
    taxsig.all<-rbind.fill(taxsig.stud,taxsig)
    taxsig.all$taxa<-gsub('k__bacteria.p__','',taxsig.all$taxa)
    taxsig.all$taxa<-factor(taxsig.all$taxa, levels=taxname.sig.s)
    taxsig.all$study<-factor(taxsig.all$study, levels=c(unique(taxsig.stud$study),"Pooled estimate"))
    taxsig.all$estimate<-taxsig.all$estimate.conbf
    taxsig$estimate<-taxsig$estimate.conbf
    taxsig$ll<-taxsig$ll.conbf
    taxsig$ul<-taxsig$ul.conbf
    rownames(taxsig.all)<-NULL
    }
  }
  if (nrow(taxsig)==0){
    display="table"
  }
  if (display=="plot"){
    if (plot=="heatmap"){
      p<-ggplot(taxsig.all, aes(study, taxa)) +
        geom_tile(aes(fill = estimate)) +
        scale_fill_gradient2(low = "blue", high = "red")+
        ylab("") +
        xlab("") +
        theme(legend.title = element_text(size = 10),
              legend.text = element_text(size = 8),
              plot.title = element_text(size=16),
              axis.title=element_text(size=14,face="bold"),
              axis.text.x = element_text(angle = 45, hjust = 1),
              legend.position="bottom") +
        labs(fill = fill.value)
      if (grid==TRUE){
        p<-ggplot(taxsig.all, aes(study, taxa)) +
          geom_tile(aes(fill = estimate)) +
          scale_fill_gradient2(low = "blue", high = "red")+
          ylab("") +
          xlab("") +
          theme(legend.title = element_blank(),
                legend.text = element_blank(),
                plot.title = element_text(size=16),
                axis.title=element_text(size=14,face="bold"),
                axis.text.x = element_blank(),
                axis.ticks.x = element_blank(),
                legend.position="none") +
          labs(fill = fill.value)
      }
    }
    if (plot=="forest"){
      p<-ggplot(data=taxsig,aes(x=estimate,y=taxa))+
        geom_point(shape=16)+
        geom_errorbarh(aes(xmin=ll,xmax=ul),height=0.0, colour="blue")+
        geom_vline(xintercept=0,linetype="dashed")+
        xlab(fill.value)
      if (grid==TRUE){
        p<-ggplot(data=taxsig,aes(x=estimate,y=taxa))+
          geom_point(shape=16)+
          geom_errorbarh(aes(xmin=ll,xmax=ul),height=0.0, colour="blue")+
          geom_vline(xintercept=0,linetype="dashed")+
          xlab(fill.value)+ylab("") +
          theme(axis.title.y=element_blank(),
                axis.text.y=element_blank())
      }
    }
    return(p)
  }
  if (display=="table"){
    taxsigo<-taxsig[order(taxsig[,paste(p.cutoff.type,showvar,sep="")]), colnames(taxsig)[grep(showvar,colnames(taxsig))]]
    taxsigo[,paste(c('estimate','ll','ul'),showvar,sep="")]<-round(taxsigo[,paste(c('estimate','ll','ul'),showvar,sep="")],digit)
    taxsigo[,paste(c('p','p.adjust'),showvar,sep="")]<-round(taxsigo[,paste(c('p','p.adjust'),showvar,sep="")],p.digit)
    return(taxsigo)
  }
  if (display=="data"){
    return(data=list(taxsig.all=taxsig.all,taxsig=taxsig))
  }
}




# kegg pathway comparison
# Author: Nhan Ho (Nov 2017)
pathway.compare<-function(pathtab,mapfile,sampleid="sampleid",pathsum="rel",stat.med="gamlss",comvar="bf",adjustvar="age.sample",longitudinal="yes",p.adjust.method="fdr",percent.filter=0.05,relabund.filter=0.00005,pooldata=FALSE,age.limit=100,age.lowerlimit=0,...){
  #value can be "rel"=relative abundance (proportion added to 1) or "log"=log2 transformed values
  #stat.med can choose "lm" (usable for both pathsum="rel" or "log") or "gamlss" (gamlss only make sense if pathsum="rel" )
  #apply to pathway summary tables already merged to mapping file and put in a list (level 2 and 3)
  #comvar need to be a factor: bf with three levels: exclusivebf, non-exclusivebf and no-bf
  # for longitudinal data, need factor variable "personid" in mapfile
  # estimates: .nebf= estimate comparing between non-exclusivebf vs. exclusivebf, .nbf=estimate comparing between no-bf vs. exclusivebf,.age=estimate for age,
  #.conbf=estimate for bf as a continuous variable (test for trend across exclusivebf, non-exclusivebf and no-bf)
  sapply(c("lme4","sjmisc", "sjPlot", "lmerTest","glmmADMB", "pscl", "MASS", "boot","betareg", "gamlss","gdata"), require, character.only = TRUE) #"rjags", "zoib",
  #pathlev<-paste("l",2:(length(pathtab)+1),sep="")
  pathlev<-paste("l",1:length(pathtab),sep="")
  estisum<-list()
  for (j in 1:length(pathlev)){
    print(j)
    samlist<-rownames(pathtab[[j]])
    #pathtab[[j]]<-as.data.frame(lapply(pathtab[[j]],as.character))
    pathtab[[j]]<-as.data.frame(lapply(pathtab[[j]],as.numeric)) #if original data are interger (! be careful if the original data are factor => can be very wrong)
    rownames(pathtab[[j]])<-samlist
    pathlist<-colnames(pathtab[[j]])
    #filter using percent.filter
    pathtest<-apply(pathtab[[j]],2,function(x){length(x[!is.na(x)&x>0])})
    pathget<-pathtest[pathtest>=percent.filter*(nrow(pathtab[[j]]))]
    #filter using relabund.filter
    pathtests<-apply(pathtab[[j]],2,function(x){sum(x,na.rm=T)/sum(pathtab[[j]])})
    pathgets<-pathtests[pathtests>relabund.filter]
    pathname<-names(pathget)[names(pathget) %in% names(pathgets)]
    if (pathsum=="rel"){
      #calculate relative abundance
      pathrel<-as.data.frame(t(apply(pathtab[[j]], 1, function(x) x / sum(x)))[,pathname])
      pathrel[,sampleid]<-rownames(pathrel)
      pathdat<-merge(subset(mapfile,age.sample<=age.limit & age.sample>=age.lowerlimit),pathrel,by=sampleid)
    }
    if (pathsum=="log"){
      # log2 transform
      pathlog<-log2(pathtab[[j]][,pathname]+1)
      pathlog[,sampleid]<-rownames(pathlog)
      pathdat<-merge(subset(mapfile,age.sample<=age.limit & age.sample>=age.lowerlimit),pathlog,by=sampleid)
    }
    pathdat[,comvar]<-drop.levels(pathdat[,comvar],reorder=FALSE) #drop missing/unused level and keep level order
    pathdat[,"comvarnum"]<-as.numeric(pathdat[,comvar])
    comvarnum<-"comvarnum"
    levcom<-levels(pathdat[,comvar])
    nlevcom<-nlevels(as.factor(as.character(pathdat[,comvar]))) # to remove empty level
    estisum[[j]]<-matrix(NA,nrow=length(pathname),ncol=20)
    colnames(estisum[[j]])<-c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","pval.adjust.nebf",
                              "estimate.nbf","se.nbf","teststat.nbf","pval.nbf","pval.adjust.nbf",
                              "estimate.age","se.age","teststat.age","pval.age","pval.adjust.age",
                              "estimate.conbf","se.conbf","teststat.conbf","pval.conbf","pval.adjust.conbf")
    rownames(estisum[[j]])<-pathname
    for (i in 1: length(pathname)){
      print(i)
        if (longitudinal=="yes"){
          #linear mixed model: not optimal test but work well
          if (stat.med=="lm" & (pathsum=="rel"|pathsum=="log")){
            fitsum.ji<-try(summary(glmer(as.formula(paste(pathname[i],paste(c(comvar,adjustvar,"(1|personid)"),collapse="+"),sep="~")), data=pathdat,family=gaussian(link="identity"))))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","estimate.nbf","se.nbf","teststat.nbf","estimate.age","se.age","teststat.age")]<-c(fitsum.ji$coefficients[2,1:3],fitsum.ji$coefficients[3,1:3],fitsum.ji$coefficients[4,1:3])
                #calculate pval
                z.nebf<-estisum[[j]][i,"estimate.nebf"]/estisum[[j]][i,"se.nebf"]
                estisum[[j]][i,"pval.nebf"]<- 2*pnorm(-abs(z.nebf))
                z.nbf<-estisum[[j]][i,"estimate.nbf"]/estisum[[j]][i,"se.nbf"]
                estisum[[j]][i,"pval.nbf"]<- 2*pnorm(-abs(z.nbf))
                z.age<-estisum[[j]][i,"estimate.age"]/estisum[[j]][i,"se.age"]
                estisum[[j]][i,"pval.age"]<- 2*pnorm(-abs(z.age))
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(glmer(as.formula(paste(pathname[i],paste(c(comvarnum,adjustvar,"(1|personid)"),collapse="+"),sep="~")), data=pathdat,family=gaussian(link="identity")))
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf")]<-fitsum.conbf.ji$coefficients[2,1:3]
                z.conbf<-estisum[[j]][i,"estimate.conbf"]/estisum[[j]][i,"se.conbf"]
                estisum[[j]][i,"pval.conbf"]<- 2*pnorm(-abs(z.conbf))
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","estimate.age","se.age","teststat.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,])
                #calculate pval
                z.nebf<-estisum[[j]][i,"estimate.nebf"]/estisum[[j]][i,"se.nebf"]
                estisum[[j]][i,"pval.nebf"]<- 2*pnorm(-abs(z.nebf))
                z.age<-estisum[[j]][i,"estimate.age"]/estisum[[j]][i,"se.age"]
                estisum[[j]][i,"pval.age"]<- 2*pnorm(-abs(z.age))
              }
            }
          }
          #Generalized Additive Models for Location Scale and Shape: Betazeroinflated family, mu link logit
          if (stat.med=="gamlss" &(pathsum=="log")){
            stop("gamlss with beta zero-inflated family should only be used for relative abundance data")
          }
          if (stat.med=="gamlss" &(pathsum=="rel")){
            testdat<-pathdat[,c(pathname[i],comvar,comvarnum,adjustvar,"personid")]
            if (nlevcom==2){
              testdat<-pathdat[,c(pathname[i],comvar,adjustvar,"personid")]
            }
            testdat<-na.omit(testdat) # dirty fix for error due to NA in GAMLSS model
            testdat[,pathname[i]][testdat[,pathname[i]]==1]<-0.9999 # dirty fix for 1 value of relative abundance in UW data (to be checked)
            if (nrow(testdat[is.na(testdat[,comvar]),])>0){
              testdat<-testdat[!is.na(testdat[,comvar]),] #dirty fix for missing values of bf in usbmk data (to be checked)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.character)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.factor)
              testdat[,comvar]<-factor(testdat[,comvar],levels=levcom)
            }
            #for pooled analysis, only run model on complete case data
            if (pooldata==TRUE){
              testdat<-na.omit(testdat)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.character)
              testdat[,c(comvar,"personid")]<-lapply(testdat[,c(comvar,"personid")],as.factor)
              testdat[,comvar]<-factor(testdat[,comvar],levels=levcom)
            }
            fitsum.ji<-try(summary(gamlss(as.formula(paste(pathname[i],paste(c(comvar,adjustvar,"random(personid)"),collapse="+"),sep="~")), family = BEZI, data = testdat, trace = FALSE),save=TRUE))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,],fitsum.ji$coef.table[4,])
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(gamlss(as.formula(paste(pathname[i],paste(c(comvarnum,adjustvar,"random(personid)"),collapse="+"),sep="~")), family = BEZI, data = testdat, trace = FALSE),save=TRUE)
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<- fitsum.conbf.ji$coef.table[2,]
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,])
              }
            }
          }
        }
        if (longitudinal=="no"){
          #linear regression: not optimal test but work
          if (stat.med=="lm"& (pathsum=="rel"|pathsum=="log")){
            fitsum.ji<-try(summary(glm(as.formula(paste(pathname[i],paste(c(comvar,adjustvar),collapse="+"),sep="~")), data=pathdat,family="gaussian")))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,],fitsum.ji$coefficients[4,])
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(glm(as.formula(paste(pathname[i],paste(c(comvarnum,adjustvar),collapse="+"),sep="~")), data=pathdat,family="gaussian"))
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<- fitsum.conbf.ji$coefficients[2,]
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coefficients[2,],fitsum.ji$coefficients[3,])
              }
            }
          }
          #Generalized Additive Models for Location Scale and Shape: Betazeroinflated family, mu link logit
          if (stat.med=="gamlss" &(pathsum=="log")){
            stop("gamlss with beta zero-inflated family should only be used for relative abundance data")
          }
          if (stat.med=="gamlss" &(pathsum=="rel")){
            testdat<-pathdat[,c(pathname[i],comvar,comvarnum,adjustvar)]
            if(nlevcom==2){
              testdat<-pathdat[,c(pathname[i],comvar,adjustvar)]
            }
            testdat<-na.omit(testdat) # dirty fix for error due to NA in GAMLSS model
            testdat[,pathname[i]][testdat[,pathname[i]]==1]<-0.9999 # dirty fix for 1 value of relative abundance in UW data (to be checked)
            testdat<-testdat[!is.na(testdat[,comvar]),] #dirty fix for missing values of bf in usbmk data (to be checked)
            fitsum.ji<-try(summary(gamlss(as.formula(paste(pathname[i],paste(c(comvar,adjustvar),collapse="+"),sep="~")), family = BEZI, data = testdat, trace = FALSE),save=TRUE))
            if (class(fitsum.ji) == "try-error") {
              cat("Error in model fit, NA introduced.\n")
              estisum[[j]][i,]<-rep(NA,ncol(estisum[[j]]))
            }
            if (class(fitsum.ji) != "try-error") {
              if (nlevcom==3){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.nbf","se.nbf","teststat.nbf","pval.nbf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,],fitsum.ji$coef.table[4,])
                #treat bf as continuous to test for trend
                fitsum.conbf.ji<-summary(gamlss(as.formula(paste(pathname[i],paste(c(comvarnum,adjustvar),collapse="+"),sep="~")), family = BEZI, data = testdat, trace = FALSE),save=TRUE)
                estisum[[j]][i,c("estimate.conbf","se.conbf","teststat.conbf","pval.conbf")]<- fitsum.conbf.ji$coef.table[2,]
              }
              if (nlevcom==2){
                estisum[[j]][i,c("estimate.nebf","se.nebf","teststat.nebf","pval.nebf","estimate.age","se.age","teststat.age","pval.age")]<-c(fitsum.ji$coef.table[2,],fitsum.ji$coef.table[3,])
              }
            }
          }
        }
      }
    estisum[[j]][,c("pval.adjust.nebf","pval.adjust.nbf","pval.adjust.age","pval.adjust.conbf")]<-apply(estisum[[j]][,c("pval.nebf","pval.nbf","pval.age","pval.conbf")],2, p.adjust, method = p.adjust.method)
    estisum[[j]]<-estisum[[j]][order(estisum[[j]][,"pval.nebf"]),]
  }
  names(estisum)<-pathlev
  return(estisum)
}


# Function to produce nice combined heatmap and forest plot for taxa and pathway relative abundance
#Author: Nhan Ho (Dec 2017)
meta.niceplot<-function(metadat,sumtype="taxa",level="main",p="p.nebf",p.adjust="p.adjust.nebf",phyla.col=c("select","rainbow"),forest.col="by.pvalue",heat.forest.width.ratio = c(1,1),leg.key.size=1,leg.text.size=8,heat.text.x.size=8,heat.text.x.angle=0,forest.axis.text.y=8,forest.axis.text.x=8,point.ratio=c(3,1),line.ratio=c(2,1)){
  #sumtype=c("taxa","path")
  #level=c("main","sub")
  #phyla.col=c("select","rainbow")
  require(ggplot2);require(gridExtra);require("gplots");require(reshape2); require(gdata)
  test<-metadat$taxsig.all
  #test$taxa<-test$id
  if (sumtype=="taxa"){
    test$esticat<-cut(test$estimate, breaks=c(-Inf, -1,-0.5,-0.1,0,0.1,0.5,1, Inf),
                      labels=c("<-1", "[-1,-0.5)","[-0.5,-0.1)","[-0.1,0)", "[0,0.1)", "[0.1,0.5)", "[0.5,1)", ">=1"))
    test$esticol<-mapvalues(test$esticat,from=c("<-1", "[-1,-0.5)","[-0.5,-0.1)","[-0.1,0)", "[0,0.1)", "[0.1,0.5)", "[0.5,1)", ">=1"),
                            to=c("#045a8d", "#2b8cbe", "#74a9cf","#bdc9e1", "#fecc5c","#fd8d3c", "#f03b20","#bd0026"))
  }
  if (sumtype=="path"){
    test$esticat<-cut(test$estimate, breaks=c(-Inf, -0.5,-0.1,-0.05,0,0.05,0.1,0.5, Inf),
                      labels=c("<-0.5)", "[-0.5,-0.1)","[-0.1,-0.05)","[-0.05,0)","[0,0.05)","[0.05,0.1)", "[0.1,0.5)", ">=0.5"))
    test$esticol<-mapvalues(test$esticat,from=c("<-0.5)", "[-0.5,-0.1)","[-0.1,-0.05)","[-0.05,0)","[0,0.05)","[0.05,0.1)", "[0.1,0.5)", ">=0.5"),
                            to=c("#045a8d", "#2b8cbe", "#74a9cf","#bdc9e1", "#fecc5c","#fd8d3c", "#f03b20","#bd0026"))
  }
  test$esticat<-drop.levels(test$esticat, reorder=FALSE)
  test$esticol<-drop.levels(test$esticol, reorder=FALSE)
  poplev<-levels(factor(test$pop))
  test$pop[is.na(test$pop)]<-"Pooled"
  test$pop<-factor(test$pop,levels=c(poplev[poplev!="Pooled"],"Pooled"))
  if (sumtype=="taxa"){
    if (level=="main"){
      test<-test[order(test$taxa,decreasing = FALSE),]
      test$taxas<-factor(test$taxa,levels=unique(test$taxa))
      test$plotvar<-test$taxas
     }
    if (level=="sub"){
      test$taxas<-sub(".c__.*f__", " ",as.character(test$taxa))
      test<-test[order(test$taxa,decreasing = FALSE),]
      test$taxas<-factor(test$taxas,levels=unique(test$taxas))
      test$taxa<-factor(test$taxa,levels=unique(test$taxa))
      test$plotvar<-test$taxas
    }
  }
  if (sumtype=="path"){
    test<-test[order(test$taxa,decreasing = FALSE),]
    test$taxas<-factor(test$taxa,levels=unique(test$taxa))
    test$plotvar<-test$taxas
  }
  test$study[is.na(test$study)]<-"Meta_analysis"
  nstudy<-length(unique(test$study[!is.na(test$study)]))
  my.lines<-data.frame(x=(nstudy-0.5), y=0.5, xend=(nstudy-0.5), yend=(length(unique(test$taxa))+0.5))
  h<-ggplot(test, aes(pop, plotvar)) +
    geom_tile(aes(fill=esticat)) +
    scale_fill_manual(breaks=levels(test$esticat),
                      values = levels(test$esticol),
                      labels = levels(test$esticat),
                      name = "log(OR)")+
    #scale_y_discrete(limits = rev(levels(test$taxas)))+
    geom_segment(data=my.lines, aes(x,y,xend=xend, yend=yend), size=2, inherit.aes=F)+
    ylab("") +xlab("")+
    theme(legend.title = element_text(size = 12,face="bold"),
          legend.text = element_text(size = leg.text.size,face="bold"),
          plot.title = element_text(size=16),
          axis.title=element_text(size=14,face="bold"),
          #axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position="left",
          plot.background = element_blank(),
          panel.grid.minor = element_blank(),
          panel.grid.major = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.y = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x =element_text(size=heat.text.x.size, angle=heat.text.x.angle, hjust = 1,face="bold",colour="black"),
          legend.key.size = unit(leg.key.size, "cm"))+
    guides(fill=guide_legend(ncol=1))
  testf<-metadat$taxsig
  #testf$taxa<-testf$id
  testf<-testf[testf$taxa %in% unique(test$taxa),]
  testf$taxa<-drop.levels(testf$taxa, reorder=FALSE)
  if (sumtype=="taxa"){
    if (level=="main"){
      testf$taxa2<-paste0(toupper(substr(as.character(testf$taxa), 1, 1)), substr(as.character(testf$taxa), 2, nchar(as.character(testf$taxa))))
      testf<-testf[order(testf$taxa,decreasing = FALSE),]
      testf$taxa2<-factor(testf$taxa2,unique(testf$taxa2))
      testf$taxa<-factor(testf$taxa,unique(testf$taxa))
      if (phyla.col=="select"){
        testf$colp<-mapvalues(testf$taxa,from=c("actinobacteria","bacteroidetes","cyanobacteria","firmicutes","fusobacteria","proteobacteria","verrucomicrobia",".thermi."),
                          to=c("#dd1c77","#31a354","#91003f","#d95f0e","#636363","#2ef0e7","#862ef0","#000"))
        testf$colp<-as.character(testf$colp)
      }
      if (phyla.col=="rainbow"){
        testf$colp<-mapvalues(testf$taxa,from=levels(testf$taxa),to=rainbow(nlevels(testf$taxa)))
        testf$colp<-as.character(testf$colp)
      }
      testf$plotvar<-testf$taxa2
    }
    if (level=="sub"){
      testf$taxas1<-sub(".c__.*f__", " ",as.character(testf$taxa))
      testf$taxas2<-sub(".*f__", "",as.character(testf$taxa))
      testf$taxas2<-paste0(toupper(substr(as.character(testf$taxas2), 1, 1)), substr(as.character(testf$taxas2), 2, nchar(as.character(testf$taxas2))))
      #replace empty truncated names by original names
      oname<-as.character(testf$taxa[testf$taxas2 %in% c("",".g__")])
      testf$taxas2[testf$taxas2 %in% c("",".g__")]<-paste0(toupper(substr(as.character(oname), 1, 1)), substr(as.character(oname), 2, nchar(as.character(oname))))
      testf<-testf[order(testf$taxa,decreasing = FALSE),]
      testf$taxas<-factor(testf$taxas2,levels=testf$taxas2)
      testf$phylum<-sub(".c__.*", "",as.character(testf$taxa))
      testf$phylum<-as.factor(testf$phylum)
      if (phyla.col=="select"){
        testf$colp<-mapvalues(testf$phylum,from=c("actinobacteria","bacteroidetes","cyanobacteria","firmicutes","fusobacteria","proteobacteria","verrucomicrobia",".thermi."),
                            to=c("#dd1c77","#31a354","#91003f","#d95f0e","#636363","#2ef0e7","#862ef0","#000"))
        testf$colp<-as.character(testf$colp)
      }
      if (phyla.col=="rainbow"){
        testf$colp<-mapvalues(testf$phylum,from=levels(testf$phylum),to=rainbow(nlevels(testf$phylum)))
        testf$colp<-as.character(testf$colp)
      }
      testf$plotvar<-testf$taxas
    }
  }
  if (sumtype=="path"){
    testf<-testf[order(testf$taxa,decreasing = FALSE),]
    testf$taxas<-factor(testf$taxa,levels=testf$taxa)
    testf$colp=1
    testf$plotvar<-testf$taxas
    }
  testf$pcut<-testf[,p]
  testf$p.adjustcut<-testf[,p.adjust]
  testf$psig<-cut(testf$pcut, breaks=c(0,0.05,1),include.lowest = TRUE, right = FALSE)
  testf$psigsize<-mapvalues(testf$psig,from=c("[0,0.05)","[0.05,1]"), to=point.ratio)
  testf$psigsize2<-mapvalues(testf$psig,from=c("[0,0.05)","[0.05,1]"), to=line.ratio)
  testf$padjustsig<-cut(testf$p.adjustcut, breaks=c(0,0.1,1),include.lowest = TRUE, right = FALSE)
  testf$estimate<-as.numeric(as.character(testf$estimate))
  testf$padjustsign<-mapvalues(testf$padjustsig,from=c("[0,0.1)","[0.1,1]"),to=c("17","16"))
  testf$padjustsize<-mapvalues(testf$padjustsig,from=c("[0,0.1)","[0.1,1]"),to=c("4","2"))
  if (sumtype=="taxa"){
    testf$esticat<-cut(testf$estimate, breaks=c(-Inf, -1,-0.5,-0.1,0,0.1,0.5,1, Inf),
                      labels=c("<-1", "[-1,-0.5)","[-0.5,-0.1)","[-0.1,0)", "[0,0.1)", "[0.1,0.5)", "[0.5,1)", ">=1"))
    testf$esticol<-mapvalues(testf$esticat,from=c("<-1", "[-1,-0.5)","[-0.5,-0.1)","[-0.1,0)", "[0,0.1)", "[0.1,0.5)", "[0.5,1)", ">=1"),
                            to=c("#045a8d", "#2b8cbe", "#74a9cf","#bdc9e1", "#fecc5c","#fd8d3c", "#f03b20","#bd0026"))
  }
  if (sumtype=="path"){
    testf$esticat<-cut(testf$estimate, breaks=c(-Inf, -0.5,-0.1,-0.05,0,0.05,0.1,0.5, Inf),
                      labels=c("<-0.5)", "[-0.5,-0.1)","[-0.1,-0.05)","[-0.05,0)","[0,0.05)","[0.05,0.1)", "[0.1,0.5)", ">=0.5"))
    testf$esticol<-mapvalues(testf$esticat,from=c("<-0.5)", "[-0.5,-0.1)","[-0.1,-0.05)","[-0.05,0)","[0,0.05)","[0.05,0.1)", "[0.1,0.5)", ">=0.5"),
                            to=c("#045a8d", "#2b8cbe", "#74a9cf","#bdc9e1", "#fecc5c","#fd8d3c", "#f03b20","#bd0026"))
  }
  testf$esticat<-drop.levels(testf$esticat, reorder=FALSE)
  testf$esticol<-drop.levels(testf$esticol, reorder=FALSE)
  # dirty truncate large estimate, LL and UL for better plot view
  testf[,c("estimate","ll","ul")]<-apply(testf[,c("estimate","ll","ul")],2,function(x){x[x>=5]=5;x[x<=-5]=-5;x})
  if (forest.col=="by.pvalue"){
    f<- ggplot(data=testf,aes(x=estimate,y=plotvar,colour=psig))+
      geom_point(shape=as.numeric(as.character(testf$padjustsign)),size=as.numeric(as.character(testf$padjustsize)))+
      scale_y_discrete(position = "right")+ #limits = rev(levels(testf$taxa2))
      geom_errorbarh(aes(xmin=ll,xmax=ul,colour=psig),height=0.0,size=1)+
      geom_vline(xintercept=0,linetype="dashed")+
      scale_colour_manual(breaks=testf$psig,values = c("red", "black"))+
      theme(legend.position="none",
            plot.background = element_blank(),
            panel.background = element_blank(),
            axis.ticks.y= element_blank(),
            axis.title = element_blank(),
            axis.text.y =element_text(size=forest.axis.text.y, colour = testf$colp,face="bold"),
            axis.text.x =element_text(size=forest.axis.text.x,face="bold",colour="black"))
  }
  if (forest.col=="by.estimate"){
    f<- ggplot(data=testf,aes(x=estimate,y=plotvar,colour=esticol))+
      geom_point(shape=as.numeric(as.character(testf$padjustsign)),size=as.numeric(as.character(testf$psigsize)))+
      scale_y_discrete(position = "right")+ #,limits = rev(levels(testf$taxa2))
      geom_errorbarh(aes(xmin=ll,xmax=ul,colour=esticol),height=0.0, size=as.numeric(as.character(testf$psigsize2)))+
      geom_vline(xintercept=0,linetype="dashed")+
      scale_colour_manual(breaks=testf$esticol,values = levels(testf$esticol))+
      theme(legend.position="none",
            plot.background = element_blank(),
            panel.background = element_blank(),
            axis.ticks.y= element_blank(),
            axis.title = element_blank(),
            axis.text.y =element_text(size=forest.axis.text.y, colour = testf$colp,face="bold"),
            axis.text.x =element_text(size=forest.axis.text.x,face="bold",colour="black"))
  }
  return(grid.arrange(h,f,nrow=1,widths = heat.forest.width.ratio))
}

# Function for microbiome age
# get share genera
# fit train model in Bangladesh training set
# predict on Bangladesh test set with plot
# model performance plot
# predict on the new study data
# comparision between groups using LME
# meta-analysis
# Author: Nhan Ho (Dec 2017)
microbiomeage<-function(l6.relabundtab){
  require(caret); require(randomForest); require(ggplot2)
  bal6<-read.delim("C:/Users/nth2111/My files/Dr Kuhn/Microbiome/data/relativematurity/tax_mapping/Subramanian_et_al_mapping_file_L6.txt")
  colnames(bal6)<-tolower(colnames(bal6))
  gba<-colnames(bal6)[grep("g__",colnames(bal6))]
  #get shared genera list of Bangladesh and other studies
  glist<-list()
  gshare<-gba
  for (i in 1: length(l6.relabundtab)){
    glist[[i]]<-colnames(l6.relabundtab[[i]])[grep("g__",colnames(l6.relabundtab[[i]]))]
    gshare<-gshare[gshare %in% glist[[i]]]
  }
  bal6.share<-bal6[,c("x.sampleid","personid","familyid","ena.libraryname","health_analysis_groups","age_in_months","sex",gshare)]
  train<-as.character(bal6.share$x.sampleid[bal6.share$ena.libraryname=="BANG_HLTHY" &bal6.share$health_analysis_groups=="Healthy Singletons"])
  test<-as.character(bal6.share$x.sampleid[bal6.share$ena.libraryname!="BANG_HLTHY" & (bal6.share$health_analysis_groups=="Healthy Singletons" | bal6.share$health_analysis_groups=="Healthy Twins Triplets") |bal6.share$health_analysis_groups=="Severe Acute Malnutrition Study"])
  age.sample<-bal6.share$age_in_months
  names(age.sample)<-bal6.share$x.sampleid
  SdataMatrix <- cbind(age.sample, bal6.share[,gshare])
  traindat<-SdataMatrix[train,]
  testdat<-SdataMatrix[test,]
  #randomForest
  set.seed(123)
  rffit<- train(age.sample ~ ., data = traindat, method = "rf",preProc = "center", proximity = TRUE)
  #predict on the Bangladesh data
  testage <- predict(rffit, newdata = testdat)
  testdat1<-cbind(sampleid=rownames(testdat),age.sample=testdat[,"age.sample"],age.predicted=testage)
  testdat2<-merge(testdat1,bal6.share, by.x="sampleid",by.y="x.sampleid")
  testdat2[,c("age.sample","age.predicted")]<-lapply(testdat2[,c("age.sample","age.predicted")],as.character)
  testdat2[,c("age.sample","age.predicted")]<-lapply(testdat2[,c("age.sample","age.predicted")],as.numeric)
  # list of share genera and relative importance
  taxim<-as.data.frame(importance(rffit$finalModel))
  taxim$genera<-rownames(taxim)
  taxim$importance<-taxim[,"IncNodePurity"]
  taxim<-taxim[order(taxim[,"IncNodePurity"],decreasing = TRUE),]
  taxim<-taxim[,c("genera","importance")]
  rownames(taxim)<-NULL
  # performance on Bangladesh data
  traindat$age.predicted <- predict(rffit, newdata = traindat)
  actual<-traindat$age.sample
  predict<-traindat$age.predicted
  R2 <- 1 - (sum((actual-predict )^2)/sum((actual-mean(actual))^2))
  R2<-round(R2,2)
  ptrain<-ggplot() +geom_point(data=traindat,aes(x=age.sample, y=age.predicted))+
    theme(legend.text = element_text(colour="black", size = 10))+
    annotate("text", x=15, y=5,label=paste("R squared =",R2,sep=" ")) +
    labs(title="Training set")+
    theme(legend.key.size = unit(0.5, "cm"),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank())+
    xlab("Chronological age (month)") +ylab("Microbiome age (month)")
  bahealthy<-testdat2[testdat2$health_analysis_groups %in% c("Healthy Singletons","Healthy Twins Triplets"),]
  actual<-bahealthy$age.sample
  predict<-bahealthy$age.predicted
  R2 <- 1 - (sum((actual-predict )^2)/sum((actual-mean(actual))^2))
  R2<-round(R2,2)
  ptest<-ggplot() +geom_point(data=bahealthy,aes(x=age.sample, y=age.predicted))+
    theme(legend.text = element_text(colour="black", size = 10))+
    annotate("text", x=15, y=5,label=paste("R squared =",R2,sep=" ")) +
    labs(title="Test set")+
    theme(legend.key.size = unit(0.5, "cm"),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank())+
    xlab("Chronological age (month)") +ylab("Microbiome age (month)")
  # predict on other data
  datshare<-list()
  predictdat<-list()
  for (i in 1: length(l6.relabundtab)){
    datshare[[i]]<-l6.relabundtab[[i]][,c("age.sample",gshare)]
    rownames(datshare[[i]])<-l6.relabundtab[[i]]$x.sampleid
    age.predicted <- predict(rffit, newdata = datshare[[i]])
    predictdat[[i]]<-merge(cbind(x.sampleid=rownames(datshare[[i]]),age.predicted=age.predicted),l6.relabundtab[[i]], by="x.sampleid")
    predictdat[[i]][,c("age.sample","age.predicted")]<-lapply(predictdat[[i]][,c("age.sample","age.predicted")],as.character)
    predictdat[[i]][,c("age.sample","age.predicted")]<-lapply(predictdat[[i]][,c("age.sample","age.predicted")],as.numeric)
  }
  names(datshare)<-names(predictdat)<-names(l6.relabundtab)
  return(list(traindat.bangledesh=traindat,testdat.bangladesh=testdat,datshare=list(bangladesh=bal6.share,otherstudy=datshare),randomforestfit=rffit,sharedgenera.importance=taxim, performanceplot=list(ptrain=ptrain,ptest=ptest),microbiomeage.bangladesh=list(all=testdat2,healthy=bahealthy),microbiomeage.otherstudy=predictdat))
}





